{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connected to Python 3.13.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e48d54-02f8-4a59-912e-3f32c726ff12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# âš¡ stage1_lstm_cv_light_tb.py (TensorBoard + ì‹œê°„ ê¸°ë¡)\n",
    "# ==========================================================\n",
    "import os, time, json, math, random, datetime, re, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, GlobalAveragePooling1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import optuna, joblib\n",
    "\n",
    "# ==========================================================\n",
    "# ì„¤ì •\n",
    "# ==========================================================\n",
    "train_path = \"./data/fixed_train_clean_v2.csv\"\n",
    "test_path  = \"./data/fixed_test_weather_full.csv\"\n",
    "\n",
    "TARGETS = [\n",
    "    \"ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)\",\n",
    "    \"ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)\",\n",
    "    \"ì§„ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)\",\n",
    "    \"ì§€ìƒì—­ë¥ (%)\",\n",
    "    \"ì§„ìƒì—­ë¥ (%)\",\n",
    "]\n",
    "\n",
    "N_SPLITS = 3\n",
    "N_TRIALS = 5\n",
    "SEED = 42\n",
    "\n",
    "LOG_BASE = \"logs_light_tb\"\n",
    "os.makedirs(LOG_BASE, exist_ok=True)\n",
    "os.makedirs(\"models_light\", exist_ok=True)\n",
    "os.makedirs(\"artifacts_light\", exist_ok=True)\n",
    "\n",
    "def set_seed(seed=SEED):\n",
    "    random.seed(seed); np.random.seed(seed); tf.random.set_seed(seed)\n",
    "set_seed()\n",
    "\n",
    "# ==========================================================\n",
    "# ìœ í‹¸ í•¨ìˆ˜\n",
    "# ==========================================================\n",
    "def tb_dir(target, fold):\n",
    "    stamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    path = os.path.join(LOG_BASE, f\"{target}_fold{fold}_{stamp}\")\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    return path\n",
    "\n",
    "def create_sequences(X, y, seq_len):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - seq_len):\n",
    "        Xs.append(X[i:i+seq_len])\n",
    "        ys.append(y[i+seq_len])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "def build_light_lstm(input_shape, params):\n",
    "    inp = Input(shape=input_shape)\n",
    "    x = LSTM(params[\"units\"], return_sequences=True, dropout=params[\"dropout\"])(inp)\n",
    "    if params[\"n_layers\"] == 2:\n",
    "        x = LSTM(params[\"units\"]//2, return_sequences=True, dropout=params[\"dropout\"])(x)\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dropout(params[\"dropout\"])(x)\n",
    "    out = Dense(1)(x)\n",
    "    model = Model(inp, out)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params[\"lr\"]), loss=\"mae\")\n",
    "    return model\n",
    "\n",
    "def preprocess_dataframe(df):\n",
    "    df = df.copy()\n",
    "    for col in [\"ì¸¡ì •ì¼ì‹œ_x\", \"ì¸¡ì •ì¼ì‹œ_y\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_datetime(df[col], errors=\"coerce\")\n",
    "            df = df.sort_values(col).reset_index(drop=True)\n",
    "            break\n",
    "    drop_cols = [\"id\", \"ì¸¡ì •ì¼ì‹œ_x\", \"ì¸¡ì •ì¼ì‹œ_y\"]\n",
    "    df = df.drop(columns=[c for c in drop_cols if c in df.columns], errors=\"ignore\")\n",
    "\n",
    "    if \"season\" in df.columns:\n",
    "        df[\"season\"] = df[\"season\"].map({\"spring\":0,\"summer\":1,\"autumn\":2,\"fall\":2,\"winter\":3}).fillna(3).astype(int)\n",
    "        df = pd.get_dummies(df, columns=[\"season\"], prefix=\"season\")\n",
    "\n",
    "    if \"ì‘ì—…ìœ í˜•\" in df.columns:\n",
    "        df = pd.get_dummies(df, columns=[\"ì‘ì—…ìœ í˜•\"], prefix=\"ì‘ì—…ìœ í˜•\")\n",
    "\n",
    "    if \"ë‚ ì”¨ì½”ë“œ\" in df.columns:\n",
    "        le = LabelEncoder()\n",
    "        df[\"ë‚ ì”¨ì½”ë“œ\"] = le.fit_transform(df[\"ë‚ ì”¨ì½”ë“œ\"].astype(str))\n",
    "\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == \"object\":\n",
    "            le = LabelEncoder()\n",
    "            df[col] = le.fit_transform(df[col].astype(str))\n",
    "    return df\n",
    "\n",
    "# ==========================================================\n",
    "# ë°ì´í„° ë¡œë“œ\n",
    "# ==========================================================\n",
    "print(\"ğŸ“‚ Loading...\")\n",
    "train = preprocess_dataframe(pd.read_csv(train_path))\n",
    "ALL_NUM = train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "feature_pool = [c for c in ALL_NUM if c not in TARGETS + [\"ì „ê¸°ìš”ê¸ˆ(ì›)\"]]\n",
    "\n",
    "# ==========================================================\n",
    "# Optuna Objective\n",
    "# ==========================================================\n",
    "def make_objective(target):\n",
    "    X_full = train[feature_pool].values.astype(float)\n",
    "    y_full = train[target].values.astype(float)\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            \"n_layers\": trial.suggest_int(\"n_layers\", 1, 2),\n",
    "            \"units\": trial.suggest_int(\"units\", 16, 64, step=16),\n",
    "            \"dropout\": trial.suggest_float(\"dropout\", 0.1, 0.4, step=0.1),\n",
    "            \"seq_len\": trial.suggest_int(\"seq_len\", 12, 48, step=12),\n",
    "            \"lr\": trial.suggest_float(\"lr\", 1e-4, 3e-3, log=True),\n",
    "            \"batch_size\": trial.suggest_categorical(\"batch_size\", [16, 32]),\n",
    "            \"epochs\": trial.suggest_int(\"epochs\", 20, 40, step=10),\n",
    "        }\n",
    "\n",
    "        tscv = TimeSeriesSplit(n_splits=N_SPLITS)\n",
    "        fold_mae = []\n",
    "        start_time = time.time()\n",
    "\n",
    "        for fold, (tr_idx, va_idx) in enumerate(tscv.split(X_full)):\n",
    "            x_scaler = StandardScaler(); y_scaler = StandardScaler()\n",
    "            X_tr = x_scaler.fit_transform(X_full[tr_idx])\n",
    "            X_va = x_scaler.transform(X_full[va_idx])\n",
    "            y_tr = y_full[tr_idx].reshape(-1,1); y_va = y_full[va_idx].reshape(-1,1)\n",
    "            y_tr_s = y_scaler.fit_transform(y_tr).ravel(); y_va_s = y_scaler.transform(y_va).ravel()\n",
    "\n",
    "            seq_len = min(params[\"seq_len\"], len(X_tr)//3)\n",
    "            X_tr_seq, y_tr_seq = create_sequences(X_tr, y_tr_s, seq_len)\n",
    "            X_va_seq, y_va_seq = create_sequences(X_va, y_va_s, seq_len)\n",
    "\n",
    "            if len(X_tr_seq)==0 or len(X_va_seq)==0:\n",
    "                return 1e9\n",
    "\n",
    "            model = build_light_lstm((seq_len, X_tr_seq.shape[-1]), params)\n",
    "            tb_logdir = tb_dir(target, fold)\n",
    "            callbacks = [\n",
    "                TensorBoard(log_dir=tb_logdir),\n",
    "                EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True),\n",
    "                ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3),\n",
    "            ]\n",
    "\n",
    "            print(f\"ğŸŸ¢ [{target}] Fold {fold+1}/{N_SPLITS} start ({params['epochs']} epochs)...\")\n",
    "            t0 = time.time()\n",
    "            model.fit(\n",
    "                X_tr_seq, y_tr_seq,\n",
    "                validation_data=(X_va_seq, y_va_seq),\n",
    "                epochs=params[\"epochs\"],\n",
    "                batch_size=params[\"batch_size\"],\n",
    "                verbose=0,\n",
    "                shuffle=False,\n",
    "                callbacks=callbacks\n",
    "            )\n",
    "            duration = time.time() - t0\n",
    "            print(f\"â±ï¸ Fold {fold+1} ì™„ë£Œ: {duration/60:.2f}ë¶„\")\n",
    "\n",
    "            y_hat_s = model.predict(X_va_seq, verbose=0).ravel()\n",
    "            y_hat = y_scaler.inverse_transform(y_hat_s.reshape(-1,1)).ravel()\n",
    "            y_true = y_scaler.inverse_transform(y_va_seq.reshape(-1,1)).ravel()\n",
    "            fold_mae.append(mean_absolute_error(y_true, y_hat))\n",
    "\n",
    "        total_time = time.time() - start_time\n",
    "        print(f\"â° ì´ í•™ìŠµì‹œê°„: {total_time/60:.2f}ë¶„\")\n",
    "        return float(np.mean(fold_mae))\n",
    "    return objective\n",
    "\n",
    "# ==========================================================\n",
    "# ì‹¤í–‰\n",
    "# ==========================================================\n",
    "metrics = {}\n",
    "for tgt in TARGETS:\n",
    "    print(f\"\\n================== Target: {tgt} ==================\")\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(make_objective(tgt), n_trials=N_TRIALS, show_progress_bar=True)\n",
    "    metrics[tgt] = {\n",
    "        \"best_mae\": study.best_value,\n",
    "        \"best_params\": study.best_trial.params\n",
    "    }\n",
    "    print(f\"ğŸ¯ {tgt} | Best MAE: {study.best_value:.4f}\")\n",
    "    print(f\"ğŸ§© Params: {study.best_trial.params}\")\n",
    "\n",
    "with open(\"artifacts_light/light_tb_metrics.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(metrics, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"\\nâœ… í•™ìŠµ ì™„ë£Œ! TensorBoardì—ì„œ ì‹œê°í™” ê°€ëŠ¥.\")\n",
    "print(f\"â–¶ tensorboard --logdir {LOG_BASE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connected to fin_ls (Python 3.10.19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f14ff13-8f4e-4ec5-ab88-12d41c98fc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ Loading...\n",
      "\n",
      "================== Target: ì „ë ¥ì‚¬ìš©ëŸ‰(kWh) ==================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 09:43:25,042] A new study created in memory with name: no-name-e82aa65b-3ea9-4f8c-a1cf-f121fcb13f1e\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŸ¢ [ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)] Fold 1/3 start (40 epochs)...\n",
      "[W 2025-10-24 09:43:25,275] Trial 0 failed with parameters: {'n_layers': 2, 'units': 48, 'dropout': 0.4, 'seq_len': 24, 'lr': 0.0001530017184762353, 'batch_size': 16, 'epochs': 40} because of the following error: FailedPreconditionError().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kbk29\\miniconda3\\envs\\fin_ls\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"<ipython-input-1-9ad80cc521c4>\", line 154, in objective\n",
      "    model.fit(\n",
      "  File \"c:\\Users\\kbk29\\miniconda3\\envs\\fin_ls\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"c:\\Users\\kbk29\\miniconda3\\envs\\fin_ls\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 6027, in raise_from_not_ok_status\n",
      "    raise core._status_to_exception(e) from None  # pylint: disable=protected-access\n",
      "tensorflow.python.framework.errors_impl.FailedPreconditionError: {{function_node __wrapped__CreateSummaryFileWriter_device_/job:localhost/replica:0/task:0/device:CPU:0}} logs_light_tb\\ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)_fold0_20251024-094325 is not a directory [Op:CreateSummaryFileWriter] name: \n",
      "[W 2025-10-24 09:43:25,277] Trial 0 failed with value None.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "{{function_node __wrapped__CreateSummaryFileWriter_device_/job:localhost/replica:0/task:0/device:CPU:0}} logs_light_tb\\ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)_fold0_20251024-094325 is not a directory [Op:CreateSummaryFileWriter] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\kbk29\\Desktop\\portfolio\\fin_LS\\base.py:183\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m================== Target: \u001b[39m\u001b[39m{\u001b[39;00mtgt\u001b[39m}\u001b[39;00m\u001b[39m ==================\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    182\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mminimize\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 183\u001b[0m study\u001b[39m.\u001b[39;49moptimize(make_objective(tgt), n_trials\u001b[39m=\u001b[39;49mN_TRIALS, show_progress_bar\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    184\u001b[0m metrics[tgt] \u001b[39m=\u001b[39m {\n\u001b[0;32m    185\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mbest_mae\u001b[39m\u001b[39m\"\u001b[39m: study\u001b[39m.\u001b[39mbest_value,\n\u001b[0;32m    186\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mbest_params\u001b[39m\u001b[39m\"\u001b[39m: study\u001b[39m.\u001b[39mbest_trial\u001b[39m.\u001b[39mparams\n\u001b[0;32m    187\u001b[0m }\n\u001b[0;32m    188\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mğŸ¯ \u001b[39m\u001b[39m{\u001b[39;00mtgt\u001b[39m}\u001b[39;00m\u001b[39m | Best MAE: \u001b[39m\u001b[39m{\u001b[39;00mstudy\u001b[39m.\u001b[39mbest_value\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\kbk29\\miniconda3\\envs\\fin_ls\\lib\\site-packages\\optuna\\study\\study.py:490\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39moptimize\u001b[39m(\n\u001b[0;32m    389\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    390\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    397\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    398\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    399\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    400\u001b[0m \n\u001b[0;32m    401\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    489\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 490\u001b[0m     _optimize(\n\u001b[0;32m    491\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    492\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[0;32m    493\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[0;32m    494\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    495\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    496\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[0;32m    497\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    498\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[0;32m    499\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[0;32m    500\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\kbk29\\miniconda3\\envs\\fin_ls\\lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         _optimize_sequential(\n\u001b[0;32m     64\u001b[0m             study,\n\u001b[0;32m     65\u001b[0m             func,\n\u001b[0;32m     66\u001b[0m             n_trials,\n\u001b[0;32m     67\u001b[0m             timeout,\n\u001b[0;32m     68\u001b[0m             catch,\n\u001b[0;32m     69\u001b[0m             callbacks,\n\u001b[0;32m     70\u001b[0m             gc_after_trial,\n\u001b[0;32m     71\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     72\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     73\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[0;32m     74\u001b[0m         )\n\u001b[0;32m     75\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\kbk29\\miniconda3\\envs\\fin_ls\\lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial_id \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    161\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\kbk29\\miniconda3\\envs\\fin_ls\\lib\\site-packages\\optuna\\study\\_optimize.py:258\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    253\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    254\u001b[0m     updated_state \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[0;32m    255\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    256\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    257\u001b[0m ):\n\u001b[1;32m--> 258\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[0;32m    259\u001b[0m \u001b[39mreturn\u001b[39;00m trial\u001b[39m.\u001b[39m_trial_id\n",
      "File \u001b[1;32mc:\\Users\\kbk29\\miniconda3\\envs\\fin_ls\\lib\\site-packages\\optuna\\study\\_optimize.py:201\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[0;32m    200\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 201\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[0;32m    202\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    203\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    204\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "File \u001b[1;32mc:\\Users\\kbk29\\Desktop\\portfolio\\fin_LS\\base.py:154\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mğŸŸ¢ [\u001b[39m\u001b[39m{\u001b[39;00mtarget\u001b[39m}\u001b[39;00m\u001b[39m] Fold \u001b[39m\u001b[39m{\u001b[39;00mfold\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mN_SPLITS\u001b[39m}\u001b[39;00m\u001b[39m start (\u001b[39m\u001b[39m{\u001b[39;00mparams[\u001b[39m'\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m epochs)...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    153\u001b[0m t0 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m--> 154\u001b[0m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    155\u001b[0m     X_tr_seq, y_tr_seq,\n\u001b[0;32m    156\u001b[0m     validation_data\u001b[39m=\u001b[39;49m(X_va_seq, y_va_seq),\n\u001b[0;32m    157\u001b[0m     epochs\u001b[39m=\u001b[39;49mparams[\u001b[39m\"\u001b[39;49m\u001b[39mepochs\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m    158\u001b[0m     batch_size\u001b[39m=\u001b[39;49mparams[\u001b[39m\"\u001b[39;49m\u001b[39mbatch_size\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m    159\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[0;32m    160\u001b[0m     shuffle\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    161\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks\n\u001b[0;32m    162\u001b[0m )\n\u001b[0;32m    163\u001b[0m duration \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m t0\n\u001b[0;32m    164\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mâ±ï¸ Fold \u001b[39m\u001b[39m{\u001b[39;00mfold\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m ì™„ë£Œ: \u001b[39m\u001b[39m{\u001b[39;00mduration\u001b[39m/\u001b[39m\u001b[39m60\u001b[39m\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39më¶„\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\kbk29\\miniconda3\\envs\\fin_ls\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[39m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\kbk29\\miniconda3\\envs\\fin_ls\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:6027\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6025\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mraise_from_not_ok_status\u001b[39m(e, name) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NoReturn:\n\u001b[0;32m   6026\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m-> 6027\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: {{function_node __wrapped__CreateSummaryFileWriter_device_/job:localhost/replica:0/task:0/device:CPU:0}} logs_light_tb\\ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)_fold0_20251024-094325 is not a directory [Op:CreateSummaryFileWriter] name: "
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# âš¡ stage1_lstm_cv_light_tb.py (TensorBoard + ì‹œê°„ ê¸°ë¡)\n",
    "# ==========================================================\n",
    "import os, time, json, math, random, datetime, re, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, GlobalAveragePooling1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import optuna, joblib\n",
    "\n",
    "# ==========================================================\n",
    "# ì„¤ì •\n",
    "# ==========================================================\n",
    "train_path = \"./data/fixed_train_clean_v2.csv\"\n",
    "test_path  = \"./data/fixed_test_weather_full.csv\"\n",
    "\n",
    "TARGETS = [\n",
    "    \"ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)\",\n",
    "    \"ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)\",\n",
    "    \"ì§„ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)\",\n",
    "    \"ì§€ìƒì—­ë¥ (%)\",\n",
    "    \"ì§„ìƒì—­ë¥ (%)\",\n",
    "]\n",
    "\n",
    "N_SPLITS = 3\n",
    "N_TRIALS = 5\n",
    "SEED = 42\n",
    "\n",
    "LOG_BASE = \"logs_light_tb\"\n",
    "os.makedirs(LOG_BASE, exist_ok=True)\n",
    "os.makedirs(\"models_light\", exist_ok=True)\n",
    "os.makedirs(\"artifacts_light\", exist_ok=True)\n",
    "\n",
    "def set_seed(seed=SEED):\n",
    "    random.seed(seed); np.random.seed(seed); tf.random.set_seed(seed)\n",
    "set_seed()\n",
    "\n",
    "# ==========================================================\n",
    "# ìœ í‹¸ í•¨ìˆ˜\n",
    "# ==========================================================\n",
    "def tb_dir(target, fold):\n",
    "    stamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    path = os.path.join(LOG_BASE, f\"{target}_fold{fold}_{stamp}\")\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    return path\n",
    "\n",
    "def create_sequences(X, y, seq_len):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - seq_len):\n",
    "        Xs.append(X[i:i+seq_len])\n",
    "        ys.append(y[i+seq_len])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "def build_light_lstm(input_shape, params):\n",
    "    inp = Input(shape=input_shape)\n",
    "    x = LSTM(params[\"units\"], return_sequences=True, dropout=params[\"dropout\"])(inp)\n",
    "    if params[\"n_layers\"] == 2:\n",
    "        x = LSTM(params[\"units\"]//2, return_sequences=True, dropout=params[\"dropout\"])(x)\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dropout(params[\"dropout\"])(x)\n",
    "    out = Dense(1)(x)\n",
    "    model = Model(inp, out)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params[\"lr\"]), loss=\"mae\")\n",
    "    return model\n",
    "\n",
    "def preprocess_dataframe(df):\n",
    "    df = df.copy()\n",
    "    for col in [\"ì¸¡ì •ì¼ì‹œ_x\", \"ì¸¡ì •ì¼ì‹œ_y\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_datetime(df[col], errors=\"coerce\")\n",
    "            df = df.sort_values(col).reset_index(drop=True)\n",
    "            break\n",
    "    drop_cols = [\"id\", \"ì¸¡ì •ì¼ì‹œ_x\", \"ì¸¡ì •ì¼ì‹œ_y\"]\n",
    "    df = df.drop(columns=[c for c in drop_cols if c in df.columns], errors=\"ignore\")\n",
    "\n",
    "    if \"season\" in df.columns:\n",
    "        df[\"season\"] = df[\"season\"].map({\"spring\":0,\"summer\":1,\"autumn\":2,\"fall\":2,\"winter\":3}).fillna(3).astype(int)\n",
    "        df = pd.get_dummies(df, columns=[\"season\"], prefix=\"season\")\n",
    "\n",
    "    if \"ì‘ì—…ìœ í˜•\" in df.columns:\n",
    "        df = pd.get_dummies(df, columns=[\"ì‘ì—…ìœ í˜•\"], prefix=\"ì‘ì—…ìœ í˜•\")\n",
    "\n",
    "    if \"ë‚ ì”¨ì½”ë“œ\" in df.columns:\n",
    "        le = LabelEncoder()\n",
    "        df[\"ë‚ ì”¨ì½”ë“œ\"] = le.fit_transform(df[\"ë‚ ì”¨ì½”ë“œ\"].astype(str))\n",
    "\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == \"object\":\n",
    "            le = LabelEncoder()\n",
    "            df[col] = le.fit_transform(df[col].astype(str))\n",
    "    return df\n",
    "\n",
    "# ==========================================================\n",
    "# ë°ì´í„° ë¡œë“œ\n",
    "# ==========================================================\n",
    "print(\"ğŸ“‚ Loading...\")\n",
    "train = preprocess_dataframe(pd.read_csv(train_path))\n",
    "ALL_NUM = train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "feature_pool = [c for c in ALL_NUM if c not in TARGETS + [\"ì „ê¸°ìš”ê¸ˆ(ì›)\"]]\n",
    "\n",
    "# ==========================================================\n",
    "# Optuna Objective\n",
    "# ==========================================================\n",
    "def make_objective(target):\n",
    "    X_full = train[feature_pool].values.astype(float)\n",
    "    y_full = train[target].values.astype(float)\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            \"n_layers\": trial.suggest_int(\"n_layers\", 1, 2),\n",
    "            \"units\": trial.suggest_int(\"units\", 16, 64, step=16),\n",
    "            \"dropout\": trial.suggest_float(\"dropout\", 0.1, 0.4, step=0.1),\n",
    "            \"seq_len\": trial.suggest_int(\"seq_len\", 12, 48, step=12),\n",
    "            \"lr\": trial.suggest_float(\"lr\", 1e-4, 3e-3, log=True),\n",
    "            \"batch_size\": trial.suggest_categorical(\"batch_size\", [16, 32]),\n",
    "            \"epochs\": trial.suggest_int(\"epochs\", 20, 40, step=10),\n",
    "        }\n",
    "\n",
    "        tscv = TimeSeriesSplit(n_splits=N_SPLITS)\n",
    "        fold_mae = []\n",
    "        start_time = time.time()\n",
    "\n",
    "        for fold, (tr_idx, va_idx) in enumerate(tscv.split(X_full)):\n",
    "            x_scaler = StandardScaler(); y_scaler = StandardScaler()\n",
    "            X_tr = x_scaler.fit_transform(X_full[tr_idx])\n",
    "            X_va = x_scaler.transform(X_full[va_idx])\n",
    "            y_tr = y_full[tr_idx].reshape(-1,1); y_va = y_full[va_idx].reshape(-1,1)\n",
    "            y_tr_s = y_scaler.fit_transform(y_tr).ravel(); y_va_s = y_scaler.transform(y_va).ravel()\n",
    "\n",
    "            seq_len = min(params[\"seq_len\"], len(X_tr)//3)\n",
    "            X_tr_seq, y_tr_seq = create_sequences(X_tr, y_tr_s, seq_len)\n",
    "            X_va_seq, y_va_seq = create_sequences(X_va, y_va_s, seq_len)\n",
    "\n",
    "            if len(X_tr_seq)==0 or len(X_va_seq)==0:\n",
    "                return 1e9\n",
    "\n",
    "            model = build_light_lstm((seq_len, X_tr_seq.shape[-1]), params)\n",
    "            tb_logdir = tb_dir(target, fold)\n",
    "            callbacks = [\n",
    "                TensorBoard(log_dir=tb_logdir),\n",
    "                EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True),\n",
    "                ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3),\n",
    "            ]\n",
    "\n",
    "            print(f\"ğŸŸ¢ [{target}] Fold {fold+1}/{N_SPLITS} start ({params['epochs']} epochs)...\")\n",
    "            t0 = time.time()\n",
    "            model.fit(\n",
    "                X_tr_seq, y_tr_seq,\n",
    "                validation_data=(X_va_seq, y_va_seq),\n",
    "                epochs=params[\"epochs\"],\n",
    "                batch_size=params[\"batch_size\"],\n",
    "                verbose=0,\n",
    "                shuffle=False,\n",
    "                callbacks=callbacks\n",
    "            )\n",
    "            duration = time.time() - t0\n",
    "            print(f\"â±ï¸ Fold {fold+1} ì™„ë£Œ: {duration/60:.2f}ë¶„\")\n",
    "\n",
    "            y_hat_s = model.predict(X_va_seq, verbose=0).ravel()\n",
    "            y_hat = y_scaler.inverse_transform(y_hat_s.reshape(-1,1)).ravel()\n",
    "            y_true = y_scaler.inverse_transform(y_va_seq.reshape(-1,1)).ravel()\n",
    "            fold_mae.append(mean_absolute_error(y_true, y_hat))\n",
    "\n",
    "        total_time = time.time() - start_time\n",
    "        print(f\"â° ì´ í•™ìŠµì‹œê°„: {total_time/60:.2f}ë¶„\")\n",
    "        return float(np.mean(fold_mae))\n",
    "    return objective\n",
    "\n",
    "# ==========================================================\n",
    "# ì‹¤í–‰\n",
    "# ==========================================================\n",
    "metrics = {}\n",
    "for tgt in TARGETS:\n",
    "    print(f\"\\n================== Target: {tgt} ==================\")\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(make_objective(tgt), n_trials=N_TRIALS, show_progress_bar=True)\n",
    "    metrics[tgt] = {\n",
    "        \"best_mae\": study.best_value,\n",
    "        \"best_params\": study.best_trial.params\n",
    "    }\n",
    "    print(f\"ğŸ¯ {tgt} | Best MAE: {study.best_value:.4f}\")\n",
    "    print(f\"ğŸ§© Params: {study.best_trial.params}\")\n",
    "\n",
    "with open(\"artifacts_light/light_tb_metrics.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(metrics, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"\\nâœ… í•™ìŠµ ì™„ë£Œ! TensorBoardì—ì„œ ì‹œê°í™” ê°€ëŠ¥.\")\n",
    "print(f\"â–¶ tensorboard --logdir {LOG_BASE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4622c1-f782-4ade-85ee-7b85ea805bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 09:44:00,987] A new study created in memory with name: no-name-69fa1478-6e56-4bb9-935b-3987f5c15f22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ Loading...\n",
      "\n",
      "================== Target: ì „ë ¥ì‚¬ìš©ëŸ‰(kWh) ==================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŸ¢ [ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)] Fold 1/3 start (20 epochs)...\n",
      "â±ï¸ Fold 1 ì™„ë£Œ: 2.31ë¶„\n",
      "ğŸŸ¢ [ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)] Fold 2/3 start (20 epochs)...\n",
      "â±ï¸ Fold 2 ì™„ë£Œ: 4.94ë¶„\n",
      "ğŸŸ¢ [ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)] Fold 3/3 start (20 epochs)...\n",
      "â±ï¸ Fold 3 ì™„ë£Œ: 6.27ë¶„\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 15.0609:  20%|â–ˆâ–ˆ        | 1/5 [13:39<54:36, 819.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â° ì´ í•™ìŠµì‹œê°„: 13.65ë¶„\n",
      "[I 2025-10-24 09:57:40,085] Trial 0 finished with value: 15.06088879294782 and parameters: {'n_layers': 2, 'units': 16, 'dropout': 0.4, 'seq_len': 36, 'lr': 0.00022715932338907853, 'batch_size': 32, 'epochs': 20}. Best is trial 0 with value: 15.06088879294782.\n",
      "ğŸŸ¢ [ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)] Fold 1/3 start (20 epochs)...\n",
      "â±ï¸ Fold 1 ì™„ë£Œ: 0.69ë¶„\n",
      "ğŸŸ¢ [ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)] Fold 2/3 start (20 epochs)...\n",
      "â±ï¸ Fold 2 ì™„ë£Œ: 1.56ë¶„\n",
      "ğŸŸ¢ [ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)] Fold 3/3 start (20 epochs)...\n",
      "â±ï¸ Fold 3 ì™„ë£Œ: 2.25ë¶„\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 15.0609:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [18:13<24:55, 498.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â° ì´ í•™ìŠµì‹œê°„: 4.57ë¶„\n",
      "[I 2025-10-24 10:02:14,073] Trial 1 finished with value: 15.652452097555965 and parameters: {'n_layers': 2, 'units': 48, 'dropout': 0.4, 'seq_len': 24, 'lr': 0.00043966627411015787, 'batch_size': 16, 'epochs': 20}. Best is trial 0 with value: 15.06088879294782.\n",
      "ğŸŸ¢ [ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)] Fold 1/3 start (40 epochs)...\n",
      "â±ï¸ Fold 1 ì™„ë£Œ: 0.34ë¶„\n",
      "ğŸŸ¢ [ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)] Fold 2/3 start (40 epochs)...\n",
      "â±ï¸ Fold 2 ì™„ë£Œ: 2.75ë¶„\n",
      "ğŸŸ¢ [ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)] Fold 3/3 start (40 epochs)...\n",
      "â±ï¸ Fold 3 ì™„ë£Œ: 3.28ë¶„\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 15.0609:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [24:38<14:53, 446.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â° ì´ í•™ìŠµì‹œê°„: 6.43ë¶„\n",
      "[I 2025-10-24 10:08:39,757] Trial 2 finished with value: 16.860487921436132 and parameters: {'n_layers': 1, 'units': 16, 'dropout': 0.2, 'seq_len': 48, 'lr': 0.00021277135686152148, 'batch_size': 32, 'epochs': 40}. Best is trial 0 with value: 15.06088879294782.\n",
      "ğŸŸ¢ [ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)] Fold 1/3 start (20 epochs)...\n",
      "â±ï¸ Fold 1 ì™„ë£Œ: 1.43ë¶„\n",
      "ğŸŸ¢ [ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)] Fold 2/3 start (20 epochs)...\n",
      "â±ï¸ Fold 2 ì™„ë£Œ: 2.36ë¶„\n",
      "ğŸŸ¢ [ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)] Fold 3/3 start (20 epochs)...\n",
      "â±ï¸ Fold 3 ì™„ë£Œ: 3.73ë¶„\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 14.9366:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [32:14<07:30, 450.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â° ì´ í•™ìŠµì‹œê°„: 7.60ë¶„\n",
      "[I 2025-10-24 10:16:15,859] Trial 3 finished with value: 14.936604750197105 and parameters: {'n_layers': 1, 'units': 64, 'dropout': 0.30000000000000004, 'seq_len': 48, 'lr': 0.0003728100321510454, 'batch_size': 16, 'epochs': 20}. Best is trial 3 with value: 14.936604750197105.\n",
      "ğŸŸ¢ [ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)] Fold 1/3 start (30 epochs)...\n",
      "â±ï¸ Fold 1 ì™„ë£Œ: 1.43ë¶„\n",
      "ğŸŸ¢ [ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)] Fold 2/3 start (30 epochs)...\n",
      "â±ï¸ Fold 2 ì™„ë£Œ: 3.14ë¶„\n",
      "ğŸŸ¢ [ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)] Fold 3/3 start (30 epochs)...\n",
      "â±ï¸ Fold 3 ì™„ë£Œ: 4.64ë¶„\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 13.9734: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [41:33<00:00, 498.61s/it]\n",
      "[I 2025-10-24 10:25:34,036] A new study created in memory with name: no-name-2d535f3e-1d5b-496d-9c8d-c16d00a59fc7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â° ì´ í•™ìŠµì‹œê°„: 9.30ë¶„\n",
      "[I 2025-10-24 10:25:34,027] Trial 4 finished with value: 13.973431541970974 and parameters: {'n_layers': 2, 'units': 64, 'dropout': 0.30000000000000004, 'seq_len': 48, 'lr': 0.0009344996792772221, 'batch_size': 32, 'epochs': 30}. Best is trial 4 with value: 13.973431541970974.\n",
      "ğŸ¯ ì „ë ¥ì‚¬ìš©ëŸ‰(kWh) | Best MAE: 13.9734\n",
      "ğŸ§© Params: {'n_layers': 2, 'units': 64, 'dropout': 0.30000000000000004, 'seq_len': 48, 'lr': 0.0009344996792772221, 'batch_size': 32, 'epochs': 30}\n",
      "\n",
      "================== Target: ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh) ==================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŸ¢ [ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)] Fold 1/3 start (30 epochs)...\n",
      "â±ï¸ Fold 1 ì™„ë£Œ: 0.33ë¶„\n",
      "ğŸŸ¢ [ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)] Fold 2/3 start (30 epochs)...\n",
      "â±ï¸ Fold 2 ì™„ë£Œ: 1.36ë¶„\n",
      "ğŸŸ¢ [ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)] Fold 3/3 start (30 epochs)...\n",
      "â±ï¸ Fold 3 ì™„ë£Œ: 1.79ë¶„\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 8.66807:  20%|â–ˆâ–ˆ        | 1/5 [03:31<14:07, 211.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â° ì´ í•™ìŠµì‹œê°„: 3.53ë¶„\n",
      "[I 2025-10-24 10:29:05,809] Trial 0 finished with value: 8.66807223896618 and parameters: {'n_layers': 2, 'units': 16, 'dropout': 0.2, 'seq_len': 12, 'lr': 0.0002697319028036083, 'batch_size': 32, 'epochs': 30}. Best is trial 0 with value: 8.66807223896618.\n",
      "ğŸŸ¢ [ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)] Fold 1/3 start (30 epochs)...\n",
      "â±ï¸ Fold 1 ì™„ë£Œ: 0.38ë¶„\n",
      "ğŸŸ¢ [ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)] Fold 2/3 start (30 epochs)...\n",
      "â±ï¸ Fold 2 ì™„ë£Œ: 1.33ë¶„\n",
      "ğŸŸ¢ [ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)] Fold 3/3 start (30 epochs)...\n",
      "â±ï¸ Fold 3 ì™„ë£Œ: 1.08ë¶„\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 8.66807:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [06:21<09:20, 186.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â° ì´ í•™ìŠµì‹œê°„: 2.82ë¶„\n",
      "[I 2025-10-24 10:31:55,232] Trial 1 finished with value: 9.167018387373428 and parameters: {'n_layers': 1, 'units': 16, 'dropout': 0.4, 'seq_len': 36, 'lr': 0.0003525176543176877, 'batch_size': 32, 'epochs': 30}. Best is trial 0 with value: 8.66807223896618.\n",
      "ğŸŸ¢ [ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)] Fold 1/3 start (30 epochs)...\n",
      "â±ï¸ Fold 1 ì™„ë£Œ: 0.84ë¶„\n",
      "ğŸŸ¢ [ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)] Fold 2/3 start (30 epochs)...\n",
      "â±ï¸ Fold 2 ì™„ë£Œ: 2.43ë¶„\n",
      "ğŸŸ¢ [ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)] Fold 3/3 start (30 epochs)...\n",
      "â±ï¸ Fold 3 ì™„ë£Œ: 4.17ë¶„\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 8.08959:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [13:51<10:14, 307.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â° ì´ í•™ìŠµì‹œê°„: 7.50ë¶„\n",
      "[I 2025-10-24 10:39:25,331] Trial 2 finished with value: 8.089594342312893 and parameters: {'n_layers': 2, 'units': 32, 'dropout': 0.2, 'seq_len': 36, 'lr': 0.0007525436097472862, 'batch_size': 32, 'epochs': 30}. Best is trial 2 with value: 8.089594342312893.\n",
      "ğŸŸ¢ [ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)] Fold 1/3 start (30 epochs)...\n",
      "â±ï¸ Fold 1 ì™„ë£Œ: 0.33ë¶„\n",
      "ğŸŸ¢ [ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)] Fold 2/3 start (30 epochs)...\n",
      "â±ï¸ Fold 2 ì™„ë£Œ: 1.41ë¶„\n",
      "ğŸŸ¢ [ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)] Fold 3/3 start (30 epochs)...\n",
      "â±ï¸ Fold 3 ì™„ë£Œ: 2.03ë¶„\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 8.08959:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [17:40<04:36, 276.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â° ì´ í•™ìŠµì‹œê°„: 3.82ë¶„\n",
      "[I 2025-10-24 10:43:14,256] Trial 3 finished with value: 8.865838385986562 and parameters: {'n_layers': 1, 'units': 48, 'dropout': 0.1, 'seq_len': 24, 'lr': 0.00019419056494163097, 'batch_size': 32, 'epochs': 30}. Best is trial 2 with value: 8.089594342312893.\n",
      "ğŸŸ¢ [ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)] Fold 1/3 start (30 epochs)...\n",
      "â±ï¸ Fold 1 ì™„ë£Œ: 0.68ë¶„\n",
      "ğŸŸ¢ [ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)] Fold 2/3 start (30 epochs)...\n",
      "â±ï¸ Fold 2 ì™„ë£Œ: 1.80ë¶„\n",
      "ğŸŸ¢ [ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)] Fold 3/3 start (30 epochs)...\n",
      "â±ï¸ Fold 3 ì™„ë£Œ: 1.78ë¶„\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 8.08959: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [22:00<00:00, 264.01s/it]\n",
      "[I 2025-10-24 10:47:34,092] A new study created in memory with name: no-name-c9e355df-2ca7-410b-bf67-e48ffcda7874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â° ì´ í•™ìŠµì‹œê°„: 4.33ë¶„\n",
      "[I 2025-10-24 10:47:34,092] Trial 4 finished with value: 8.149150156761719 and parameters: {'n_layers': 2, 'units': 64, 'dropout': 0.2, 'seq_len': 12, 'lr': 0.0008174658447852776, 'batch_size': 16, 'epochs': 30}. Best is trial 2 with value: 8.089594342312893.\n",
      "ğŸ¯ ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh) | Best MAE: 8.0896\n",
      "ğŸ§© Params: {'n_layers': 2, 'units': 32, 'dropout': 0.2, 'seq_len': 36, 'lr': 0.0007525436097472862, 'batch_size': 32, 'epochs': 30}\n",
      "\n",
      "================== Target: ì§„ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh) ==================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŸ¢ [ì§„ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)] Fold 1/3 start (30 epochs)...\n",
      "â±ï¸ Fold 1 ì™„ë£Œ: 1.77ë¶„\n",
      "ğŸŸ¢ [ì§„ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)] Fold 2/3 start (30 epochs)...\n",
      "â±ï¸ Fold 2 ì™„ë£Œ: 1.72ë¶„\n",
      "ğŸŸ¢ [ì§„ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)] Fold 3/3 start (30 epochs)...\n",
      "â±ï¸ Fold 3 ì™„ë£Œ: 2.88ë¶„\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 3.22021:  20%|â–ˆâ–ˆ        | 1/5 [06:29<25:59, 389.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â° ì´ í•™ìŠµì‹œê°„: 6.50ë¶„\n",
      "[I 2025-10-24 10:54:04,070] Trial 0 finished with value: 3.2202097918979127 and parameters: {'n_layers': 2, 'units': 64, 'dropout': 0.30000000000000004, 'seq_len': 36, 'lr': 0.0004354242234752913, 'batch_size': 32, 'epochs': 30}. Best is trial 0 with value: 3.2202097918979127.\n",
      "ğŸŸ¢ [ì§„ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)] Fold 1/3 start (40 epochs)...\n",
      "â±ï¸ Fold 1 ì™„ë£Œ: 0.98ë¶„\n",
      "ğŸŸ¢ [ì§„ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)] Fold 2/3 start (40 epochs)...\n",
      "â±ï¸ Fold 2 ì™„ë£Œ: 1.19ë¶„\n",
      "ğŸŸ¢ [ì§„ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)] Fold 3/3 start (40 epochs)...\n",
      "â±ï¸ Fold 3 ì™„ë£Œ: 1.02ë¶„\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 3.22021:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [09:44<13:45, 275.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â° ì´ í•™ìŠµì‹œê°„: 3.25ë¶„\n",
      "[I 2025-10-24 10:57:19,004] Trial 1 finished with value: 3.2224532016777085 and parameters: {'n_layers': 1, 'units': 16, 'dropout': 0.2, 'seq_len': 48, 'lr': 0.000667089190057908, 'batch_size': 32, 'epochs': 40}. Best is trial 0 with value: 3.2202097918979127.\n",
      "ğŸŸ¢ [ì§„ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)] Fold 1/3 start (40 epochs)...\n",
      "â±ï¸ Fold 1 ì™„ë£Œ: 1.26ë¶„\n",
      "ğŸŸ¢ [ì§„ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)] Fold 2/3 start (40 epochs)...\n",
      "â±ï¸ Fold 2 ì™„ë£Œ: 0.90ë¶„\n",
      "ğŸŸ¢ [ì§„ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)] Fold 3/3 start (40 epochs)...\n",
      "â±ï¸ Fold 3 ì™„ë£Œ: 1.52ë¶„\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 3.19941:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [13:28<08:23, 251.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â° ì´ í•™ìŠµì‹œê°„: 3.73ë¶„\n",
      "[I 2025-10-24 11:01:02,854] Trial 2 finished with value: 3.1994084043674538 and parameters: {'n_layers': 1, 'units': 16, 'dropout': 0.30000000000000004, 'seq_len': 36, 'lr': 0.0026265798990159615, 'batch_size': 16, 'epochs': 40}. Best is trial 2 with value: 3.1994084043674538.\n",
      "ğŸŸ¢ [ì§„ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)] Fold 1/3 start (20 epochs)...\n",
      "â±ï¸ Fold 1 ì™„ë£Œ: 0.47ë¶„\n",
      "ğŸŸ¢ [ì§„ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)] Fold 2/3 start (20 epochs)...\n",
      "â±ï¸ Fold 2 ì™„ë£Œ: 0.75ë¶„\n",
      "ğŸŸ¢ [ì§„ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)] Fold 3/3 start (20 epochs)...\n",
      "â±ï¸ Fold 3 ì™„ë£Œ: 0.87ë¶„\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 3.19941:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [15:36<03:22, 202.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â° ì´ í•™ìŠµì‹œê°„: 2.13ë¶„\n",
      "[I 2025-10-24 11:03:10,784] Trial 3 finished with value: 3.2467887084127667 and parameters: {'n_layers': 1, 'units': 16, 'dropout': 0.4, 'seq_len': 24, 'lr': 0.0005448099962529975, 'batch_size': 32, 'epochs': 20}. Best is trial 2 with value: 3.1994084043674538.\n",
      "ğŸŸ¢ [ì§„ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)] Fold 1/3 start (40 epochs)...\n",
      "â±ï¸ Fold 1 ì™„ë£Œ: 1.35ë¶„\n",
      "ğŸŸ¢ [ì§„ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)] Fold 2/3 start (40 epochs)...\n",
      "â±ï¸ Fold 2 ì™„ë£Œ: 1.87ë¶„\n",
      "ğŸŸ¢ [ì§„ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)] Fold 3/3 start (40 epochs)...\n",
      "â±ï¸ Fold 3 ì™„ë£Œ: 2.06ë¶„\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 3.19941: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [20:56<00:00, 251.29s/it]\n",
      "[I 2025-10-24 11:08:30,572] A new study created in memory with name: no-name-e3a6b630-e404-4280-9ca4-ba0f4d3c68e6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â° ì´ í•™ìŠµì‹œê°„: 5.33ë¶„\n",
      "[I 2025-10-24 11:08:30,572] Trial 4 finished with value: 3.355036177680027 and parameters: {'n_layers': 1, 'units': 16, 'dropout': 0.1, 'seq_len': 36, 'lr': 0.000733671091655316, 'batch_size': 16, 'epochs': 40}. Best is trial 2 with value: 3.1994084043674538.\n",
      "ğŸ¯ ì§„ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh) | Best MAE: 3.1994\n",
      "ğŸ§© Params: {'n_layers': 1, 'units': 16, 'dropout': 0.30000000000000004, 'seq_len': 36, 'lr': 0.0026265798990159615, 'batch_size': 16, 'epochs': 40}\n",
      "\n",
      "================== Target: ì§€ìƒì—­ë¥ (%) ==================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŸ¢ [ì§€ìƒì—­ë¥ (%)] Fold 1/3 start (40 epochs)...\n",
      "â±ï¸ Fold 1 ì™„ë£Œ: 0.25ë¶„\n",
      "ğŸŸ¢ [ì§€ìƒì—­ë¥ (%)] Fold 2/3 start (40 epochs)...\n",
      "â±ï¸ Fold 2 ì™„ë£Œ: 0.59ë¶„\n",
      "ğŸŸ¢ [ì§€ìƒì—­ë¥ (%)] Fold 3/3 start (40 epochs)...\n",
      "â±ï¸ Fold 3 ì™„ë£Œ: 0.58ë¶„\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 6.49669:  20%|â–ˆâ–ˆ        | 1/5 [01:26<05:46, 86.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â° ì´ í•™ìŠµì‹œê°„: 1.44ë¶„\n",
      "[I 2025-10-24 11:09:57,213] Trial 0 finished with value: 6.496686901306681 and parameters: {'n_layers': 1, 'units': 32, 'dropout': 0.30000000000000004, 'seq_len': 12, 'lr': 0.0028415692149211967, 'batch_size': 32, 'epochs': 40}. Best is trial 0 with value: 6.496686901306681.\n",
      "ğŸŸ¢ [ì§€ìƒì—­ë¥ (%)] Fold 1/3 start (20 epochs)...\n",
      "â±ï¸ Fold 1 ì™„ë£Œ: 0.67ë¶„\n",
      "ğŸŸ¢ [ì§€ìƒì—­ë¥ (%)] Fold 2/3 start (20 epochs)...\n",
      "â±ï¸ Fold 2 ì™„ë£Œ: 3.31ë¶„\n",
      "ğŸŸ¢ [ì§€ìƒì—­ë¥ (%)] Fold 3/3 start (20 epochs)...\n",
      "â±ï¸ Fold 3 ì™„ë£Œ: 4.70ë¶„\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 5.70433:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [10:13<17:16, 345.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â° ì´ í•™ìŠµì‹œê°„: 8.78ë¶„\n",
      "[I 2025-10-24 11:18:43,751] Trial 1 finished with value: 5.704329132437009 and parameters: {'n_layers': 2, 'units': 32, 'dropout': 0.1, 'seq_len': 36, 'lr': 0.002547698797570022, 'batch_size': 16, 'epochs': 20}. Best is trial 1 with value: 5.704329132437009.\n",
      "ğŸŸ¢ [ì§€ìƒì—­ë¥ (%)] Fold 1/3 start (30 epochs)...\n",
      "â±ï¸ Fold 1 ì™„ë£Œ: 0.48ë¶„\n",
      "ğŸŸ¢ [ì§€ìƒì—­ë¥ (%)] Fold 2/3 start (30 epochs)...\n",
      "â±ï¸ Fold 2 ì™„ë£Œ: 0.57ë¶„\n",
      "ğŸŸ¢ [ì§€ìƒì—­ë¥ (%)] Fold 3/3 start (30 epochs)...\n",
      "â±ï¸ Fold 3 ì™„ë£Œ: 2.22ë¶„\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 5.70433:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [13:30<09:15, 277.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â° ì´ í•™ìŠµì‹œê°„: 3.30ë¶„\n",
      "[I 2025-10-24 11:22:01,529] Trial 2 finished with value: 6.487405777841772 and parameters: {'n_layers': 1, 'units': 32, 'dropout': 0.4, 'seq_len': 12, 'lr': 0.0006867316590756235, 'batch_size': 16, 'epochs': 30}. Best is trial 1 with value: 5.704329132437009.\n",
      "ğŸŸ¢ [ì§€ìƒì—­ë¥ (%)] Fold 1/3 start (40 epochs)...\n",
      "â±ï¸ Fold 1 ì™„ë£Œ: 0.67ë¶„\n",
      "ğŸŸ¢ [ì§€ìƒì—­ë¥ (%)] Fold 2/3 start (40 epochs)...\n",
      "â±ï¸ Fold 2 ì™„ë£Œ: 0.69ë¶„\n",
      "ğŸŸ¢ [ì§€ìƒì—­ë¥ (%)] Fold 3/3 start (40 epochs)...\n",
      "â±ï¸ Fold 3 ì™„ë£Œ: 1.07ë¶„\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 5.70433:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [15:58<03:46, 226.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â° ì´ í•™ìŠµì‹œê°„: 2.46ë¶„\n",
      "[I 2025-10-24 11:24:29,444] Trial 3 finished with value: 7.025505254559012 and parameters: {'n_layers': 1, 'units': 48, 'dropout': 0.4, 'seq_len': 24, 'lr': 0.0011963693013192361, 'batch_size': 16, 'epochs': 40}. Best is trial 1 with value: 5.704329132437009.\n",
      "ğŸŸ¢ [ì§€ìƒì—­ë¥ (%)] Fold 1/3 start (40 epochs)...\n",
      "â±ï¸ Fold 1 ì™„ë£Œ: 1.53ë¶„\n",
      "ğŸŸ¢ [ì§€ìƒì—­ë¥ (%)] Fold 2/3 start (40 epochs)...\n",
      "â±ï¸ Fold 2 ì™„ë£Œ: 2.10ë¶„\n",
      "ğŸŸ¢ [ì§€ìƒì—­ë¥ (%)] Fold 3/3 start (40 epochs)...\n",
      "â±ï¸ Fold 3 ì™„ë£Œ: 3.21ë¶„\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 5.70433: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [22:52<00:00, 274.50s/it]\n",
      "[I 2025-10-24 11:31:23,077] A new study created in memory with name: no-name-e2343572-1b9d-44bb-a85d-fdb65fb7074c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â° ì´ í•™ìŠµì‹œê°„: 6.89ë¶„\n",
      "[I 2025-10-24 11:31:23,061] Trial 4 finished with value: 6.235382187469661 and parameters: {'n_layers': 1, 'units': 64, 'dropout': 0.4, 'seq_len': 36, 'lr': 0.0001702966193975864, 'batch_size': 16, 'epochs': 40}. Best is trial 1 with value: 5.704329132437009.\n",
      "ğŸ¯ ì§€ìƒì—­ë¥ (%) | Best MAE: 5.7043\n",
      "ğŸ§© Params: {'n_layers': 2, 'units': 32, 'dropout': 0.1, 'seq_len': 36, 'lr': 0.002547698797570022, 'batch_size': 16, 'epochs': 20}\n",
      "\n",
      "================== Target: ì§„ìƒì—­ë¥ (%) ==================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŸ¢ [ì§„ìƒì—­ë¥ (%)] Fold 1/3 start (20 epochs)...\n",
      "â±ï¸ Fold 1 ì™„ë£Œ: 1.62ë¶„\n",
      "ğŸŸ¢ [ì§„ìƒì—­ë¥ (%)] Fold 2/3 start (20 epochs)...\n",
      "â±ï¸ Fold 2 ì™„ë£Œ: 1.51ë¶„\n",
      "ğŸŸ¢ [ì§„ìƒì—­ë¥ (%)] Fold 3/3 start (20 epochs)...\n",
      "â±ï¸ Fold 3 ì™„ë£Œ: 2.22ë¶„\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 14.3089:  20%|â–ˆâ–ˆ        | 1/5 [05:27<21:50, 327.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â° ì´ í•™ìŠµì‹œê°„: 5.46ë¶„\n",
      "[I 2025-10-24 11:36:50,662] Trial 0 finished with value: 14.3089284255578 and parameters: {'n_layers': 2, 'units': 64, 'dropout': 0.30000000000000004, 'seq_len': 48, 'lr': 0.0028966433886301103, 'batch_size': 32, 'epochs': 20}. Best is trial 0 with value: 14.3089284255578.\n",
      "ğŸŸ¢ [ì§„ìƒì—­ë¥ (%)] Fold 1/3 start (20 epochs)...\n",
      "â±ï¸ Fold 1 ì™„ë£Œ: 0.77ë¶„\n",
      "ğŸŸ¢ [ì§„ìƒì—­ë¥ (%)] Fold 2/3 start (20 epochs)...\n",
      "â±ï¸ Fold 2 ì™„ë£Œ: 1.33ë¶„\n",
      "ğŸŸ¢ [ì§„ìƒì—­ë¥ (%)] Fold 3/3 start (20 epochs)...\n",
      "â±ï¸ Fold 3 ì™„ë£Œ: 2.14ë¶„\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 14.0587:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [09:45<14:20, 286.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â° ì´ í•™ìŠµì‹œê°„: 4.31ë¶„\n",
      "[I 2025-10-24 11:41:08,992] Trial 1 finished with value: 14.058677485299354 and parameters: {'n_layers': 2, 'units': 16, 'dropout': 0.2, 'seq_len': 12, 'lr': 0.00020754629174470434, 'batch_size': 16, 'epochs': 20}. Best is trial 1 with value: 14.058677485299354.\n",
      "ğŸŸ¢ [ì§„ìƒì—­ë¥ (%)] Fold 1/3 start (40 epochs)...\n",
      "â±ï¸ Fold 1 ì™„ë£Œ: 1.34ë¶„\n",
      "ğŸŸ¢ [ì§„ìƒì—­ë¥ (%)] Fold 2/3 start (40 epochs)...\n",
      "â±ï¸ Fold 2 ì™„ë£Œ: 1.40ë¶„\n",
      "ğŸŸ¢ [ì§„ìƒì—­ë¥ (%)] Fold 3/3 start (40 epochs)...\n",
      "â±ï¸ Fold 3 ì™„ë£Œ: 2.73ë¶„\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 13.3665:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [15:16<10:13, 306.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â° ì´ í•™ìŠµì‹œê°„: 5.51ë¶„\n",
      "[I 2025-10-24 11:46:39,410] Trial 2 finished with value: 13.36654680957546 and parameters: {'n_layers': 1, 'units': 32, 'dropout': 0.4, 'seq_len': 24, 'lr': 0.0023554660046714642, 'batch_size': 16, 'epochs': 40}. Best is trial 2 with value: 13.36654680957546.\n",
      "ğŸŸ¢ [ì§„ìƒì—­ë¥ (%)] Fold 1/3 start (20 epochs)...\n",
      "â±ï¸ Fold 1 ì™„ë£Œ: 0.56ë¶„\n",
      "ğŸŸ¢ [ì§„ìƒì—­ë¥ (%)] Fold 2/3 start (20 epochs)...\n",
      "â±ï¸ Fold 2 ì™„ë£Œ: 0.90ë¶„\n",
      "ğŸŸ¢ [ì§„ìƒì—­ë¥ (%)] Fold 3/3 start (20 epochs)...\n",
      "â±ï¸ Fold 3 ì™„ë£Œ: 0.82ë¶„\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 13.3665:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [17:36<04:01, 241.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â° ì´ í•™ìŠµì‹œê°„: 2.34ë¶„\n",
      "[I 2025-10-24 11:48:59,737] Trial 3 finished with value: 13.802949411591428 and parameters: {'n_layers': 2, 'units': 32, 'dropout': 0.30000000000000004, 'seq_len': 12, 'lr': 0.0005047788891489342, 'batch_size': 32, 'epochs': 20}. Best is trial 2 with value: 13.36654680957546.\n",
      "ğŸŸ¢ [ì§„ìƒì—­ë¥ (%)] Fold 1/3 start (40 epochs)...\n",
      "â±ï¸ Fold 1 ì™„ë£Œ: 0.57ë¶„\n",
      "ğŸŸ¢ [ì§„ìƒì—­ë¥ (%)] Fold 2/3 start (40 epochs)...\n",
      "â±ï¸ Fold 2 ì™„ë£Œ: 1.71ë¶„\n",
      "ğŸŸ¢ [ì§„ìƒì—­ë¥ (%)] Fold 3/3 start (40 epochs)...\n",
      "â±ï¸ Fold 3 ì™„ë£Œ: 3.39ë¶„\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 13.3665: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [23:19<00:00, 279.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â° ì´ í•™ìŠµì‹œê°„: 5.72ë¶„\n",
      "[I 2025-10-24 11:54:42,965] Trial 4 finished with value: 13.759181039598253 and parameters: {'n_layers': 1, 'units': 16, 'dropout': 0.2, 'seq_len': 48, 'lr': 0.0008481763621480341, 'batch_size': 16, 'epochs': 40}. Best is trial 2 with value: 13.36654680957546.\n",
      "ğŸ¯ ì§„ìƒì—­ë¥ (%) | Best MAE: 13.3665\n",
      "ğŸ§© Params: {'n_layers': 1, 'units': 32, 'dropout': 0.4, 'seq_len': 24, 'lr': 0.0023554660046714642, 'batch_size': 16, 'epochs': 40}\n",
      "\n",
      "âœ… í•™ìŠµ ì™„ë£Œ! TensorBoardì—ì„œ ì‹œê°í™” ê°€ëŠ¥.\n",
      "â–¶ tensorboard --logdir logs_light_tb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# âš¡ stage1_lstm_cv_light_tb_safe.py\n",
    "# âœ… ì•ˆì „í•œ TensorBoard ê²½ë¡œ + ì‹œê°„ ê¸°ë¡ + ê²½ëŸ‰ LSTM\n",
    "# ==========================================================\n",
    "import os, time, json, math, random, datetime, re, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, GlobalAveragePooling1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import optuna, joblib\n",
    "\n",
    "# ==========================================================\n",
    "# ì„¤ì •\n",
    "# ==========================================================\n",
    "train_path = \"./data/fixed_train_clean_v2.csv\"\n",
    "test_path  = \"./data/fixed_test_weather_full.csv\"\n",
    "\n",
    "TARGETS = [\n",
    "    \"ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)\",\n",
    "    \"ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)\",\n",
    "    \"ì§„ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)\",\n",
    "    \"ì§€ìƒì—­ë¥ (%)\",\n",
    "    \"ì§„ìƒì—­ë¥ (%)\",\n",
    "]\n",
    "\n",
    "N_SPLITS = 3\n",
    "N_TRIALS = 5\n",
    "SEED = 42\n",
    "\n",
    "LOG_BASE = \"logs_light_tb\"\n",
    "os.makedirs(LOG_BASE, exist_ok=True)\n",
    "os.makedirs(\"models_light\", exist_ok=True)\n",
    "os.makedirs(\"artifacts_light\", exist_ok=True)\n",
    "\n",
    "def set_seed(seed=SEED):\n",
    "    random.seed(seed); np.random.seed(seed); tf.random.set_seed(seed)\n",
    "set_seed()\n",
    "\n",
    "# ==========================================================\n",
    "# âœ… ì•ˆì „í•œ TensorBoard ë””ë ‰í† ë¦¬ ìƒì„± í•¨ìˆ˜\n",
    "# ==========================================================\n",
    "def tb_dir(target, fold):\n",
    "    # íŠ¹ìˆ˜ë¬¸ì, í•œê¸€, ê³µë°± ì œê±° â†’ ì˜ë¬¸+ìˆ«ì+_ ë§Œ ë‚¨ê¹€\n",
    "    safe_target = re.sub(r\"[^a-zA-Z0-9_]+\", \"_\", str(target))\n",
    "    stamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    path = os.path.join(LOG_BASE, f\"{safe_target}_fold{fold}_{stamp}\")\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    return path\n",
    "\n",
    "# ==========================================================\n",
    "# ìœ í‹¸ í•¨ìˆ˜\n",
    "# ==========================================================\n",
    "def create_sequences(X, y, seq_len):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - seq_len):\n",
    "        Xs.append(X[i:i+seq_len])\n",
    "        ys.append(y[i+seq_len])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "def build_light_lstm(input_shape, params):\n",
    "    inp = Input(shape=input_shape)\n",
    "    x = LSTM(params[\"units\"], return_sequences=True, dropout=params[\"dropout\"])(inp)\n",
    "    if params[\"n_layers\"] == 2:\n",
    "        x = LSTM(params[\"units\"]//2, return_sequences=True, dropout=params[\"dropout\"])(x)\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dropout(params[\"dropout\"])(x)\n",
    "    out = Dense(1)(x)\n",
    "    model = Model(inp, out)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params[\"lr\"]), loss=\"mae\")\n",
    "    return model\n",
    "\n",
    "def preprocess_dataframe(df):\n",
    "    df = df.copy()\n",
    "    for col in [\"ì¸¡ì •ì¼ì‹œ_x\", \"ì¸¡ì •ì¼ì‹œ_y\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_datetime(df[col], errors=\"coerce\")\n",
    "            df = df.sort_values(col).reset_index(drop=True)\n",
    "            break\n",
    "    drop_cols = [\"id\", \"ì¸¡ì •ì¼ì‹œ_x\", \"ì¸¡ì •ì¼ì‹œ_y\"]\n",
    "    df = df.drop(columns=[c for c in drop_cols if c in df.columns], errors=\"ignore\")\n",
    "\n",
    "    if \"season\" in df.columns:\n",
    "        df[\"season\"] = df[\"season\"].map({\"spring\":0,\"summer\":1,\"autumn\":2,\"fall\":2,\"winter\":3}).fillna(3).astype(int)\n",
    "        df = pd.get_dummies(df, columns=[\"season\"], prefix=\"season\")\n",
    "\n",
    "    if \"ì‘ì—…ìœ í˜•\" in df.columns:\n",
    "        df = pd.get_dummies(df, columns=[\"ì‘ì—…ìœ í˜•\"], prefix=\"ì‘ì—…ìœ í˜•\")\n",
    "\n",
    "    if \"ë‚ ì”¨ì½”ë“œ\" in df.columns:\n",
    "        le = LabelEncoder()\n",
    "        df[\"ë‚ ì”¨ì½”ë“œ\"] = le.fit_transform(df[\"ë‚ ì”¨ì½”ë“œ\"].astype(str))\n",
    "\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == \"object\":\n",
    "            le = LabelEncoder()\n",
    "            df[col] = le.fit_transform(df[col].astype(str))\n",
    "    return df\n",
    "\n",
    "# ==========================================================\n",
    "# ë°ì´í„° ë¡œë“œ\n",
    "# ==========================================================\n",
    "print(\"ğŸ“‚ Loading...\")\n",
    "train = preprocess_dataframe(pd.read_csv(train_path))\n",
    "ALL_NUM = train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "feature_pool = [c for c in ALL_NUM if c not in TARGETS + [\"ì „ê¸°ìš”ê¸ˆ(ì›)\"]]\n",
    "\n",
    "# ==========================================================\n",
    "# Optuna Objective\n",
    "# ==========================================================\n",
    "def make_objective(target):\n",
    "    X_full = train[feature_pool].values.astype(float)\n",
    "    y_full = train[target].values.astype(float)\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            \"n_layers\": trial.suggest_int(\"n_layers\", 1, 2),\n",
    "            \"units\": trial.suggest_int(\"units\", 16, 64, step=16),\n",
    "            \"dropout\": trial.suggest_float(\"dropout\", 0.1, 0.4, step=0.1),\n",
    "            \"seq_len\": trial.suggest_int(\"seq_len\", 12, 48, step=12),\n",
    "            \"lr\": trial.suggest_float(\"lr\", 1e-4, 3e-3, log=True),\n",
    "            \"batch_size\": trial.suggest_categorical(\"batch_size\", [16, 32]),\n",
    "            \"epochs\": trial.suggest_int(\"epochs\", 20, 40, step=10),\n",
    "        }\n",
    "\n",
    "        tscv = TimeSeriesSplit(n_splits=N_SPLITS)\n",
    "        fold_mae = []\n",
    "        start_time = time.time()\n",
    "\n",
    "        for fold, (tr_idx, va_idx) in enumerate(tscv.split(X_full)):\n",
    "            x_scaler = StandardScaler(); y_scaler = StandardScaler()\n",
    "            X_tr = x_scaler.fit_transform(X_full[tr_idx])\n",
    "            X_va = x_scaler.transform(X_full[va_idx])\n",
    "            y_tr = y_full[tr_idx].reshape(-1,1); y_va = y_full[va_idx].reshape(-1,1)\n",
    "            y_tr_s = y_scaler.fit_transform(y_tr).ravel(); y_va_s = y_scaler.transform(y_va).ravel()\n",
    "\n",
    "            seq_len = min(params[\"seq_len\"], len(X_tr)//3)\n",
    "            X_tr_seq, y_tr_seq = create_sequences(X_tr, y_tr_s, seq_len)\n",
    "            X_va_seq, y_va_seq = create_sequences(X_va, y_va_s, seq_len)\n",
    "\n",
    "            if len(X_tr_seq)==0 or len(X_va_seq)==0:\n",
    "                return 1e9\n",
    "\n",
    "            model = build_light_lstm((seq_len, X_tr_seq.shape[-1]), params)\n",
    "            tb_logdir = tb_dir(target, fold)\n",
    "            callbacks = [\n",
    "                TensorBoard(log_dir=tb_logdir),\n",
    "                EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True),\n",
    "                ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3),\n",
    "            ]\n",
    "\n",
    "            print(f\"ğŸŸ¢ [{target}] Fold {fold+1}/{N_SPLITS} start ({params['epochs']} epochs)...\")\n",
    "            t0 = time.time()\n",
    "            model.fit(\n",
    "                X_tr_seq, y_tr_seq,\n",
    "                validation_data=(X_va_seq, y_va_seq),\n",
    "                epochs=params[\"epochs\"],\n",
    "                batch_size=params[\"batch_size\"],\n",
    "                verbose=0,\n",
    "                shuffle=False,\n",
    "                callbacks=callbacks\n",
    "            )\n",
    "            duration = time.time() - t0\n",
    "            print(f\"â±ï¸ Fold {fold+1} ì™„ë£Œ: {duration/60:.2f}ë¶„\")\n",
    "\n",
    "            y_hat_s = model.predict(X_va_seq, verbose=0).ravel()\n",
    "            y_hat = y_scaler.inverse_transform(y_hat_s.reshape(-1,1)).ravel()\n",
    "            y_true = y_scaler.inverse_transform(y_va_seq.reshape(-1,1)).ravel()\n",
    "            fold_mae.append(mean_absolute_error(y_true, y_hat))\n",
    "\n",
    "        total_time = time.time() - start_time\n",
    "        print(f\"â° ì´ í•™ìŠµì‹œê°„: {total_time/60:.2f}ë¶„\")\n",
    "        return float(np.mean(fold_mae))\n",
    "    return objective\n",
    "\n",
    "# ==========================================================\n",
    "# ì‹¤í–‰\n",
    "# ==========================================================\n",
    "metrics = {}\n",
    "for tgt in TARGETS:\n",
    "    print(f\"\\n================== Target: {tgt} ==================\")\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(make_objective(tgt), n_trials=N_TRIALS, show_progress_bar=True)\n",
    "    metrics[tgt] = {\n",
    "        \"best_mae\": study.best_value,\n",
    "        \"best_params\": study.best_trial.params\n",
    "    }\n",
    "    print(f\"ğŸ¯ {tgt} | Best MAE: {study.best_value:.4f}\")\n",
    "    print(f\"ğŸ§© Params: {study.best_trial.params}\")\n",
    "\n",
    "with open(\"artifacts_light/light_tb_metrics.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(metrics, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"\\nâœ… í•™ìŠµ ì™„ë£Œ! TensorBoardì—ì„œ ì‹œê°í™” ê°€ëŠ¥.\")\n",
    "print(f\"â–¶ tensorboard --logdir {LOG_BASE}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fin_ls",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

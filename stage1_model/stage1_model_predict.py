# ==========================================================
# âš¡ stage1_model_predict.py
# âœ… Stage1 í•™ìŠµëœ ëª¨ë¸ë¡œ testì…‹ ì˜ˆì¸¡ â†’ test_with_stage1.csv ì €ì¥
# ==========================================================
import os, json, joblib, torch
import numpy as np
import pandas as pd
from tqdm import tqdm
from sklearn.preprocessing import StandardScaler
from torch.utils.data import Dataset, DataLoader
from stage1_model_train_autolog import LSTMAttention, SeqDataset, preprocess_dataframe, TARGETS, DEVICE

# ----------------------------------------------------------
# ê²½ë¡œ ì„¤ì •
# ----------------------------------------------------------
BASE_DIR  = os.path.dirname(os.path.abspath(__file__))
DATA_DIR  = os.path.join(BASE_DIR, "../data")
MODEL_DIR = os.path.join(BASE_DIR, "stage1_model")

test_path = os.path.join(DATA_DIR, "fixed_test_weather_full.csv")
save_path = os.path.join(DATA_DIR, "fixed_test_stage1_pred.csv")

# ----------------------------------------------------------
# ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
# ----------------------------------------------------------
print("ğŸ“‚ test ë°ì´í„° ë¡œë“œ ì¤‘...")
test_df = preprocess_dataframe(pd.read_csv(test_path))
print(f"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ | shape = {test_df.shape}")

# ----------------------------------------------------------
# ìˆ«ìí˜• feature pool êµ¬ì„±
# ----------------------------------------------------------
ALL_NUM = test_df.select_dtypes(include=[np.number]).columns.tolist()
feature_pool = [c for c in ALL_NUM if c not in TARGETS + ["ì „ê¸°ìš”ê¸ˆ(ì›)"]]
X_full = test_df[feature_pool].values.astype(float)

# ----------------------------------------------------------
# ì‹œí€€ìŠ¤ ë°ì´í„°ì…‹ ìƒì„± í•¨ìˆ˜
# ----------------------------------------------------------
class SimpleDataset(Dataset):
    def __init__(self, X, seq_len):
        self.X, self.seq_len = X, seq_len
    def __len__(self):
        return len(self.X) - self.seq_len
    def __getitem__(self, idx):
        return torch.tensor(self.X[idx:idx+self.seq_len], dtype=torch.float32)

# ----------------------------------------------------------
# íƒ€ê¹ƒë³„ ëª¨ë¸ ë¡œë“œ ë° ì˜ˆì¸¡
# ----------------------------------------------------------
for i, target in enumerate(TARGETS, 1):
    model_dir = os.path.join(MODEL_DIR, f"model_{i}")
    if not os.path.exists(model_dir):
        print(f"âš ï¸ {target} ëª¨ë¸ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {model_dir}")
        continue

    print(f"\nğŸ” [{i}/{len(TARGETS)}] {target} ì˜ˆì¸¡ ì‹œì‘...")

    # ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
    x_scaler = joblib.load(os.path.join(model_dir, "scaler_x.pkl"))
    y_scaler = joblib.load(os.path.join(model_dir, "scaler_y.pkl"))

    # feature ìŠ¤ì¼€ì¼ë§
    X_scaled = x_scaler.transform(X_full)

    # ì†ì‹¤ ì •ë³´ ë¡œë“œ â†’ seq_len ì¶”ì¶œ
    try:
        with open(os.path.join(model_dir, "losses.json"), "r", encoding="utf-8") as f:
            losses = json.load(f)
        # foldë³„ seq_lenì€ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ê°€ì¥ ì§§ì€ ê°’ ì‚¬ìš©
        seq_len = 12
    except:
        seq_len = 12

    # ëª¨ë¸ íŒŒë¼ë¯¸í„° ë³µì›
    with open(os.path.join(MODEL_DIR, "metrics.json"), "r", encoding="utf-8") as f:
        meta = json.load(f)
    params = meta[target]["params"]

    # ëª¨ë¸ ìƒì„± ë° ê°€ì¤‘ì¹˜ ë¡œë“œ
    model = LSTMAttention(X_scaled.shape[1], params).to(DEVICE)
    model.load_state_dict(torch.load(os.path.join(model_dir, "best_model.pt"), map_location=DEVICE))
    model.eval()

    # ì‹œí€€ìŠ¤ ê¸°ë°˜ ì˜ˆì¸¡
    ds = SimpleDataset(X_scaled, seq_len)
    dl = DataLoader(ds, batch_size=params["batch_size"], shuffle=False)

    preds = []
    with torch.no_grad():
        for Xb in tqdm(dl, desc=f"{target} predicting"):
            Xb = Xb.to(DEVICE)
            y_pred = model(Xb).cpu().numpy()
            preds.append(y_pred)

    preds = np.concatenate(preds).ravel()
    preds_inv = y_scaler.inverse_transform(preds.reshape(-1, 1)).ravel()

    # ê¸¸ì´ ë§ì¶”ê¸°: seq_len offset ë§Œí¼ ì•ì— NaN
    pred_full = np.concatenate([np.full(seq_len, np.nan), preds_inv])

    # test_dfì— ì»¬ëŸ¼ ì¶”ê°€
    test_df[f"{target}_pred"] = pred_full

    print(f"âœ… {target} ì˜ˆì¸¡ ì™„ë£Œ | ì˜ˆì¸¡ì¹˜ {np.isnan(pred_full).sum()}ê°œ NaN, shape={len(pred_full)}")

# ----------------------------------------------------------
# ê²°ê³¼ ì €ì¥
# ----------------------------------------------------------
test_df.to_csv(save_path, index=False, encoding="utf-8-sig")
print(f"\nğŸ’¾ ì €ì¥ ì™„ë£Œ: {save_path}")
